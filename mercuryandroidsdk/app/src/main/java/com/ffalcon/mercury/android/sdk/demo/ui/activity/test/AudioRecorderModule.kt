package com.ffalcon.mercury.android.sdk.demo.ui.activity.test

import android.content.Context
import android.media.AudioFormat
import android.media.AudioManager
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import kotlin.concurrent.thread
import kotlin.math.log10
import kotlin.math.sqrt

/**
 * AudioRecorderModuleï¼šæ”¯æŒé™éŸ³æ£€æµ‹ + å®æ—¶ç¯å¢ƒåˆ†è´æ˜¾ç¤º + è‡ªåŠ¨ASR_END
 */
class AudioRecorderModule {

    companion object {
        private const val TAG = "AudioRecorderModule"
    }

    private var audioManager: AudioManager? = null
    private var audioRecord: AudioRecord? = null
    private var bufferSizeInBytes: Int = 512
    @Volatile private var isRecording = false

    // --- è¯­éŸ³æ´»åŠ¨æ£€æµ‹å‚æ•° ---
    private var silenceThresholdDb = 45.0       // å®é™…ç¯å¢ƒï¼šä¸€èˆ¬ -35~-25 ä¼šæ¯”è¾ƒåˆé€‚
    private var silenceTimeoutMs = 900L
    private var speaking = false
    private var lastSpeechTime = 0L

    private var lastDbLogTime = 0L
    private val dbWindow = ArrayDeque<Double>()
    private val smoothWindow = 5  // æœ€è¿‘5å¸§å–å¹³å‡

    var currentMode: String = "TALKING"

    fun start(
        context: Context,
        sampleRateInHz: Int = 16000,
        channelConfig: Int = AudioFormat.CHANNEL_IN_MONO,
        audioFormat: Int = AudioFormat.ENCODING_PCM_16BIT,
        bufferSizeInBytes: Int = 2048,
        sink: AudioDataSender
    ) {
        this.bufferSizeInBytes = bufferSizeInBytes

        audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
        audioManager?.setParameters("audio_source_record=record_origin3")

        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            sampleRateInHz,
            channelConfig,
            audioFormat,
            this.bufferSizeInBytes
        )

        if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
            Log.e(TAG, "AudioRecord initialization failed")
            sink.onError(IllegalStateException("AudioRecord init failed"))
            return
        }

        audioRecord?.startRecording()
        isRecording = true
        speaking = false
        lastSpeechTime = System.currentTimeMillis()

        Log.i(TAG, "ğŸ™ å¼€å§‹å½•éŸ³ (mode=$currentMode) buffer=$bufferSizeInBytes")

        thread(start = true) {
            val audioBuffer = ByteArray(bufferSizeInBytes)
            try {
                while (isRecording && audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    val bytesRead = audioRecord?.read(audioBuffer, 0, bufferSizeInBytes) ?: 0
                    if (bytesRead > 0) {
                        sink.onAudioData(audioBuffer, bytesRead)
                        if (currentMode == "TALKING") {
                            processVoiceLevel(audioBuffer, bytesRead, sink)
                        }
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "å½•éŸ³å¼‚å¸¸: ${e.message}")
                sink.onError(e)
            } finally {
                sink.onClose()
            }
        }
    }

    /**
     * è®¡ç®—éŸ³é‡å¹¶æ‰“å°å®æ—¶åˆ†è´
     */
    private fun processVoiceLevel(data: ByteArray, length: Int, sink: AudioDataSender) {
        var sum = 0.0
        for (i in 0 until length step 2) {
            val sample = (data[i + 1].toInt() shl 8) or (data[i].toInt() and 0xFF)
            sum += (sample * sample).toDouble()
        }

        val rms = sqrt(sum / (length / 2))
        val db = 20 * log10(rms.coerceAtLeast(1.0))  // ç›¸å¯¹åˆ†è´ï¼ˆéç»å¯¹å£°å‹å€¼ï¼‰

        // --- å¹³æ»‘ dB ---
        if (dbWindow.size >= smoothWindow) dbWindow.removeFirst()
        dbWindow.addLast(db)
        val avgDb = dbWindow.average()

        val now = System.currentTimeMillis()

        // å®šæœŸæ‰“å°ç¯å¢ƒéŸ³åˆ†è´
        if (now - lastDbLogTime > 500) {
            lastDbLogTime = now
//            Log.d(TAG, "ğŸ“Š å®æ—¶ç¯å¢ƒéŸ³é‡çº¦ï¼š${"%.1f".format(avgDb)} dB (é˜ˆå€¼=$silenceThresholdDb)")
        }

        if (avgDb > silenceThresholdDb) {
            if (!speaking) {
                Log.d(TAG, "ğŸ—£ æ£€æµ‹åˆ°å¼€å§‹è¯´è¯ (db=${"%.1f".format(avgDb)})")
                speaking = true
            }
            lastSpeechTime = now
        } else {
            if (speaking && now - lastSpeechTime > silenceTimeoutMs) {
                speaking = false
                Log.i(TAG, "ğŸ¤« æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå‘é€ ASR_END (db=${"%.1f".format(avgDb)})")
                sink.sendAsrEnd()
            }
        }
    }

    fun stop() {
        isRecording = false
        try {
            audioRecord?.let { record ->
                if (record.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    record.stop()
                }
                record.release()
                audioRecord = null
            }
            audioManager?.setParameters("audio_source_record=off")
            Log.i(TAG, "ğŸ›‘ åœæ­¢å½•éŸ³")
        } catch (e: Exception) {
            Log.e(TAG, "åœæ­¢å½•éŸ³å¼‚å¸¸: ${e.message}")
        }
    }
}