package com.ffalcon.mercury.android.sdk.demo.ui.activity.test.audio

import android.content.Context
import android.media.AudioFormat
import android.media.AudioManager
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import kotlin.concurrent.thread
import kotlin.math.log10
import kotlin.math.sqrt

/**
 * AudioRecorderModuleï¼š
 * æ”¯æŒè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆå¯å¼€å…³ï¼‰
 */
class AudioRecorderModule {

    companion object {
        private const val TAG = "AudioRecorderModule"
    }

    enum class VoiceDetectionMode {
        ENABLED,   // å¼€å¯è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆå‘ ASR_ENDï¼‰
        DISABLED   // ä»…é‡‡é›†éŸ³é¢‘ï¼Œä¸æ£€æµ‹è¯­éŸ³çŠ¶æ€
    }

    private var audioManager: AudioManager? = null
    private var audioRecord: AudioRecord? = null
    private var bufferSizeInBytes: Int = 512
    @Volatile private var isRecording = false

    private var enableVoiceDetection = true

    // --- è¯­éŸ³æ´»åŠ¨æ£€æµ‹å‚æ•° ---
    private var silenceThresholdDb = 45.0
    private var silenceTimeoutMs = 900L
    private var speaking = false
    private var lastSpeechTime = 0L

    private var lastDbLogTime = 0L
    private val dbWindow = ArrayDeque<Double>()
    private val smoothWindow = 5

    //========================= Basic Func =========================
    fun start(
        context: Context,
        sampleRateInHz: Int = 16000,
        channelConfig: Int = AudioFormat.CHANNEL_IN_MONO,
        audioFormat: Int = AudioFormat.ENCODING_PCM_16BIT,
        bufferSizeInBytes: Int = 2048,
        sink: AudioDataSender,
        voiceDetectionMode: VoiceDetectionMode = VoiceDetectionMode.ENABLED // ğŸ†• æ§åˆ¶å¼€å…³
    ) {
        this.bufferSizeInBytes = bufferSizeInBytes
        this.enableVoiceDetection = (voiceDetectionMode == VoiceDetectionMode.ENABLED)

        audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
        audioManager?.setParameters("audio_source_record=record_origin3")

        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            sampleRateInHz,
            channelConfig,
            audioFormat,
            this.bufferSizeInBytes
        )

        if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
            Log.e(TAG, "AudioRecord initialization failed")
            sink.onError(IllegalStateException("AudioRecord init failed"))
            return
        }

        audioRecord?.startRecording()
        isRecording = true
        speaking = false
        lastSpeechTime = System.currentTimeMillis()

        Log.i(TAG, "ğŸ™ å¼€å§‹å½•éŸ³ buffer=$bufferSizeInBytes æ£€æµ‹å¼€å…³=$enableVoiceDetection")

        thread(start = true) {
            val audioBuffer = ByteArray(bufferSizeInBytes)
            try {
                while (isRecording && audioRecord?.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    val bytesRead = audioRecord?.read(audioBuffer, 0, bufferSizeInBytes) ?: 0
                    if (bytesRead > 0) {
                        sink.onAudioData(audioBuffer, bytesRead)
                        if (enableVoiceDetection) {
                            processVoiceLevel(audioBuffer, bytesRead, sink)
                        }
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "å½•éŸ³å¼‚å¸¸: ${e.message}")
                sink.onError(e)
            } finally {
                sink.onClose()
            }
        }
    }

    fun stop() {
        isRecording = false
        try {
            audioRecord?.let { record ->
                if (record.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                    record.stop()
                }
                record.release()
                audioRecord = null
            }
            audioManager?.setParameters("audio_source_record=off")
            Log.i(TAG, "ğŸ›‘ åœæ­¢å½•éŸ³")
        } catch (e: Exception) {
            Log.e(TAG, "åœæ­¢å½•éŸ³å¼‚å¸¸: ${e.message}")
        }
    }

    //========================= Voice Detection =========================
    private fun processVoiceLevel(data: ByteArray, length: Int, sink: AudioDataSender) {
        var sum = 0.0
        for (i in 0 until length step 2) {
            val sample = (data[i + 1].toInt() shl 8) or (data[i].toInt() and 0xFF)
            sum += (sample * sample).toDouble()
        }

        val rms = sqrt(sum / (length / 2))
        val db = 20 * log10(rms.coerceAtLeast(1.0))

        if (dbWindow.size >= smoothWindow) dbWindow.removeFirst()
        dbWindow.addLast(db)
        val avgDb = dbWindow.average()
        val now = System.currentTimeMillis()

        if (avgDb > silenceThresholdDb) {
            if (!speaking) {
                Log.d(TAG, "ğŸ—£ æ£€æµ‹åˆ°å¼€å§‹è¯´è¯ (db=${"%.1f".format(avgDb)})")
                speaking = true
            }
            lastSpeechTime = now
        } else {
            if (speaking && now - lastSpeechTime > silenceTimeoutMs) {
                speaking = false
                Log.i(TAG, "ğŸ¤« æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ, å‘é€ ASR_END (db=${"%.1f".format(avgDb)})")
                sink.sendAsrEnd()
            }
        }
    }
}